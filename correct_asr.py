from pprint import pprint
asr_data = [{"text": " just time 哎，", "start": 4090, "end": 6470, "text_seg": "just time 哎 ", "ts_list": [[4090, 4330], [4470, 4875], [6250, 6470]]}, {"text": "那个成本是多少啊？", "start": 6470, "end": 7890, "text_seg": "那 个 成 本 是 多 少 啊 ", "ts_list": [[6470, 6570], [6570, 6710], [6710, 6870], [6870, 7050], [7050, 7190], [7190, 7410], [7410, 7650], [7650, 7890]]}, {"text": "就是如果你要买一段纳斯达克的广告，", "start": 7890, "end": 10370, "text_seg": "就 是 如 果 你 要 买 一 段 纳 斯 达 克 的 广 告 ", "ts_list": [[7970, 8130], [8130, 8310], [8310, 8410], [8410, 8530], [8530, 8650], [8650, 8770], [8770, 8950], [8950, 9030], [9030, 9210], [9210, 9370], [9370, 9570], [9570, 9730], [9730, 9830], [9830, 9970], [9970, 10130], [10130, 10370]]}, {"text": "绝对不用十万块，", "start": 10370, "end": 11870, "text_seg": "绝 对 不 用 十 万 块 ", "ts_list": [[10590, 10730], [10730, 10850], [10850, 10970], [10970, 11210], [11210, 11390], [11390, 11630], [11630, 11870]]}, {"text": "你就可以做一个礼拜了。", "start": 11870, "end": 13315, "text_seg": "你 就 可 以 做 一 个 礼 拜 了 ", "ts_list": [[11870, 11970], [11970, 12090], [12090, 12210], [12210, 12290], [12290, 12470], [12470, 12570], [12570, 12710], [12710, 12870], [12870, 13110], [13110, 13315]]}, {"text": "欢迎收听备忘录。", "start": 13315, "end": 20940, "text_seg": "欢 迎 收 听 备 忘 录 ", "ts_list": [[19360, 19560], [19560, 19800], [19820, 19980], [19980, 20220], [20300, 20460], [20460, 20700], [20700, 20940]]}, {"text": "你好，", "start": 20940, "end": 21540, "text_seg": "你 好 ", "ts_list": [[21140, 21300], [21300, 21540]]}, {"text": "我是贝斯。", "start": 21540, "end": 22140, "text_seg": "我 是 贝 斯 ", "ts_list": [[21600, 21700], [21700, 21840], [21840, 21940], [21940, 22140]]}, {"text": "李倩林从二零幺七年往前的二十七年时间里，", "start": 22140, "end": 26200, "text_seg": "李 倩 林 从 二 零 幺 七 年 往 前 的 二 十 七 年 时 间 里 ", "ts_list": [[22140, 22300], [22300, 22420], [22420, 22660], [23080, 23320], [23400, 23560], [23560, 23760], [23760, 23920], [23920, 24100], [24100, 24340], [24480, 24640], [24640, 24880], [24880, 24980], [24980, 25060], [25060, 25240], [25240, 25420], [25420, 25620], [25620, 25780], [25780, 25960], [25960, 26200]]}, {"text": "我一直服务于全球最大的广告集团的 BPP 曾经担任的 BPP 集团中国区的 CEO 我目前的身份是一名投资者，", "start": 26200, "end": 35800, "text_seg": "我 一 直 服 务 于 全 球 最 大 的 广 告 集 团 的 BPP 曾 经 担 任 的 BPP 集 团 中 国 区 的 CEO 我 目 前 的 身 份 是 一 名 投 资 者 ", "ts_list": [[26320, 26480], [26480, 26620], [26620, 26760], [26760, 26920], [26920, 27100], [27100, 27339], [27360, 27520], [27520, 27760], [27780, 28000], [28000, 28120], [28120, 28260], [28260, 28360], [28360, 28560], [28560, 28720], [28720, 28960], [29080, 29220], [29220, 29740], [30040, 30220], [30220, 30460], [30460, 30580], [30580, 30820], [30820, 30940], [30940, 31380], [31380, 31540], [31540, 31780], [31840, 31940], [31940, 32120], [32120, 32240], [32240, 32380], [32380, 32980], [33360, 33520], [33520, 33620], [33620, 33740], [33740, 33880], [33880, 34040], [34040, 34280], [34280, 34460], [34460, 34700], [34780, 34900], [34900, 35140], [35140, 35380], [35640, 35800]]}, {"text": "运营着一家由我自己创立的早期战略风险投资 readin link 贝西投资协作体。", "start": 35800, "end": 41920, "text_seg": "运 营 着 一 家 由 我 自 己 创 立 的 早 期 战 略 风 险 投 资 readin link 贝 西 投 资 协 作 体 ", "ts_list": [[35800, 35980], [35980, 36120], [36120, 36220], [36220, 36420], [36420, 36580], [36580, 36780], [36780, 36880], [36880, 37080], [37080, 37240], [37240, 37480], [37480, 37600], [37600, 37700], [37700, 37920], [37920, 38160], [38240, 38400], [38400, 38600], [38600, 38700], [38700, 38940], [38960, 39120], [39120, 39360], [39580, 39920], [39920, 40300], [40420, 40600], [40600, 40840], [40940, 41080], [41080, 41300], [41300, 41440], [41440, 41680], [41680, 41920]]}, {"text": "大家好，", "start": 41920, "end": 42700, "text_seg": "大 家 好 ", "ts_list": [[42220, 42340], [42340, 42460], [42460, 42700]]}, {"text": "我是坚妮刘宇静一个长期关注广告营销行业的媒体人。", "start": 42700, "end": 46500, "text_seg": "我 是 坚 妮 刘 宇 静 一 个 长 期 关 注 广 告 营 销 行 业 的 媒 体 人 ", "ts_list": [[42720, 42880], [42880, 43020], [43020, 43120], [43120, 43260], [43260, 43380], [43380, 43500], [43500, 43740], [44040, 44160], [44160, 44300], [44300, 44460], [44460, 44660], [44660, 44820], [44820, 45020], [45020, 45120], [45120, 45280], [45280, 45420], [45420, 45560], [45560, 45720], [45720, 45840], [45840, 45960], [45960, 46080], [46080, 46260], [46260, 46500]]}, {"text": "我会和贝斯一起联合主持这个节目观察。", "start": 46500, "end": 49920, "text_seg": "我 会 和 贝 斯 一 起 联 合 主 持 这 个 节 目 观 察 ", "ts_list": [[46840, 46980], [46980, 47100], [47100, 47300], [47300, 47400], [47400, 47620], [47620, 47760], [47760, 47900], [47900, 48060], [48060, 48260], [48260, 48360], [48360, 48540], [48540, 48660], [48660, 48800], [48800, 48960], [48960, 49200], [49560, 49740], [49740, 49920]]}, {"text": "有趣的创意是我的工作，", "start": 49920, "end": 51400, "text_seg": "有 趣 的 创 意 是 我 的 工 作 ", "ts_list": [[49920, 50040], [50040, 50220], [50220, 50360], [50360, 50500], [50500, 50680], [50680, 50820], [50820, 50920], [50920, 51020], [51020, 51159], [51159, 51400]]}, {"text": "也是我的兴趣所在。", "start": 51400, "end": 52840, "text_seg": "也 是 我 的 兴 趣 所 在 ", "ts_list": [[51640, 51760], [51760, 51940], [51940, 52040], [52040, 52140], [52140, 52300], [52300, 52440], [52440, 52600], [52600, 52840]]}, {"text": "在全新升级的备忘录中，", "start": 52840, "end": 55240, "text_seg": "在 全 新 升 级 的 备 忘 录 中 ", "ts_list": [[53440, 53640], [53640, 53800], [53800, 54000], [54000, 54220], [54220, 54400], [54400, 54540], [54540, 54640], [54640, 54820], [54820, 55000], [55000, 55240]]}, {"text": "我们关注广告营销行业的前世与晋升，", "start": 55240, "end": 58300, "text_seg": "我 们 关 注 广 告 营 销 行 业 的 前 世 与 晋 升 ", "ts_list": [[55340, 55480], [55480, 55580], [55580, 55720], [55720, 55960], [56040, 56200], [56200, 56420], [56420, 56560], [56560, 56760], [56760, 56920], [56920, 57100], [57100, 57240], [57240, 57460], [57460, 57700], [57700, 57900], [57900, 58060], [58060, 58300]]}, {"text": "关注科技如何？", "start": 58300, "end": 60010, "text_seg": "关 注 科 技 如 何 ", "ts_list": [[58660, 58840], [58840, 59040], [59040, 59280], [59320, 59560], [59560, 59680], [59680, 60010]]}]

speaker_data = {
    "text": [[0.0, 0.45, 1], [3.84, 5.19, 1], [6.0, 10.48, 2], [10.48, 13.44, 1], [19.15, 42.24, 4], [42.24, 52.86, 5],
             [52.86, 60.01, 4]]}

# Convert speaker_data time to milliseconds to match ASR data
for speaker_segment in speaker_data["text"]:
    speaker_segment[0] = speaker_segment[0] * 1000
    speaker_segment[1] = speaker_segment[1] * 1000


def merge_single_word_segments(output_data):
    merged_data = []

    i = 0
    while i < len(output_data):
        segment = output_data[i]

        # Check if it's a single-word segment and the next segment has the same speaker
        if len(segment["text"].strip()) == 1:
            merged_segment = {
                "text": segment["text"],
                "start": segment["start"],
                "end": segment["end"],
                "speaker": segment["speaker"]
            }

            # Try to merge with subsequent segments
            while i + 1 < len(output_data) and len(output_data[i+1]["text"].split()) == 1 and output_data[i+1]["speaker"] == merged_segment["speaker"]:
                merged_segment["text"] += " " + output_data[i+1]["text"]
                merged_segment["end"] = output_data[i+1]["end"]
                i += 1

            merged_data.append(merged_segment)
        else:
            merged_data.append(segment)

        i += 1

    return merged_data

def find_speaker_for_ts(ts, speaker_data):
    for segment in speaker_data["text"]:
        if ts >= segment[0] and ts <= segment[1]:
            return segment[2]
    return None


output_data = []

for segment in asr_data:
    previous_speaker = None
    text_list = segment['text_seg'].split()
    modified = False  # Track if the segment is split

    for idx, ts_segment in enumerate(segment['ts_list']):
        current_speaker = find_speaker_for_ts(ts_segment[0], speaker_data)

        if previous_speaker is None:
            previous_speaker = current_speaker

        # If speaker changes in the middle of a segment
        if current_speaker != previous_speaker:
            modified = True
            new_seg = {
                "text": ' '.join(text_list[:idx]),
                "start": segment['start'],
                "end": ts_segment[0],
                "speaker": previous_speaker
            }
            output_data.append(new_seg)

            segment['start'] = ts_segment[0]
            text_list = text_list[idx:]

            previous_speaker = current_speaker

    # Append the last or only segment
    if modified:
        new_seg = {
            "text": ' '.join(text_list),
            "start": segment['start'],
            "end": segment['end'],
            "speaker": previous_speaker
        }
    else:
        # If not modified, use the original text value
        new_seg = {
            "text": segment['text'],
            "start": segment['start'],
            "end": segment['end'],
            "speaker": previous_speaker
        }
    output_data.append(new_seg)

output_data = merge_single_word_segments(output_data)


# Group by speaker while preserving the time order
final_output = []

current_speaker_data = None
for item in output_data:
    if current_speaker_data and current_speaker_data["speaker"] == item["speaker"]:
        current_speaker_data["sentences"].append({
            "text": item["text"],
            "start": item["start"],
            "end": item["end"],
            "speaker": item["speaker"]
        })
    else:
        if current_speaker_data:
            final_output.append(current_speaker_data)
        current_speaker_data = {"speaker": item["speaker"], "sentences": [{
            "text": item["text"],
            "start": item["start"],
            "end": item["end"],
            "speaker": item["speaker"]
        }]}

if current_speaker_data:
    final_output.append(current_speaker_data)

print(final_output)